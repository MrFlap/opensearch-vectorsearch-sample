{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-cache-dir opensearch-py python-dotenv boto3 tqdm h5py matplotlib ipywidgets jedi ipython sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sentence Transformer model Example\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#Our sentences we like to encode\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.', \n",
    "    'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "#Print the embeddings\n",
    "for sentence, embedding in zip(sentences, sentence_embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")\n",
    "print(model)\n",
    "dimension = model.get_sentence_embedding_dimension()\n",
    "print(f\"Model dimension is : {dimension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "import os\n",
    "\n",
    "\n",
    "res = load_dotenv(\"environment.txt\")\n",
    "\n",
    "OS_HOST = os.getenv('OS_HOST')\n",
    "OS_PORT = os.getenv('OS_PORT')\n",
    "OS_USER = os.getenv('USER_NAME')\n",
    "OS_PASSWORD = os.getenv('PASSWORD')\n",
    "\n",
    "\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': OS_HOST, 'port': OS_PORT}],\n",
    "    http_compress = True, # enables gzip compression for request bodies\n",
    "    http_auth = (OS_USER, OS_PASSWORD),\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    timeout=6000,\n",
    "    pool_maxsize = 20\n",
    ")\n",
    "\n",
    "print(client.info())\n",
    "hybrid_search_index_name = os.getenv('HYBRID_SEARCH_INDEX_NAME', \"hybrid_search_index\")\n",
    "print(f\"hybrid search index name from env is : {hybrid_search_index_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(index_name, dimension):\n",
    "    index_mappings = {\n",
    "        \"settings\": {\n",
    "            \"index\": {\n",
    "                \"knn\": True,\n",
    "            }\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"embeddings\": {\n",
    "                    \"type\": \"knn_vector\",\n",
    "                    \"dimension\": dimension,\n",
    "                    \"method\": {\n",
    "                        \"name\": \"hnsw\",\n",
    "                        \"space_type\": \"l2\",\n",
    "                        \"engine\": \"faiss\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if client.indices.exists(index=index_name):\n",
    "        response = client.indices.delete(index=index_name)\n",
    "        print(f\"Deleting the index. Response : {response}\")\n",
    "\n",
    "    response = client.indices.create(index=index_name, body=index_mappings)\n",
    "    print(f\"Creating the index. Response : {response}\")\n",
    "\n",
    "create_index(hybrid_search_index_name, dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for Hybrid Search\n",
    "dataset = [\n",
    "    {\n",
    "      \"text\": \"The quick brown fox jumps over the lazy dog.\",\n",
    "    },\n",
    "    {\n",
    "      \"text\": \"A journey of a thousand miles begins with a single step.\",\n",
    "    },\n",
    "    {\n",
    "      \"text\": \"In the midst of winter, I found there was, within me, an invincible summer.\",\n",
    "    },\n",
    "    {\n",
    "      \"text\": \"To be yourself in a world that is constantly trying to make you something else is the greatest accomplishment.\",\n",
    "    },\n",
    "    {\n",
    "      \"text\": \"The only limit to our realization of tomorrow will be our doubts of today.\",\n",
    "    },\n",
    "    {\n",
    "      \"text\": \"Success is not final, failure is not fatal: It is the courage to continue that counts.\",\n",
    "    },\n",
    "    {\n",
    "      \"text\": \"Life is really simple, but we insist on making it complicated.\",\n",
    "    },\n",
    "    {\n",
    "      \"text\": \"Believe you can and you're halfway there.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "for data in dataset:\n",
    "    data['embedding'] = list(model.encode(data['text']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest data\n",
    "from tqdm.notebook import tqdm\n",
    "from opensearchpy.helpers import bulk\n",
    "\n",
    "global_errors = []\n",
    "for key, data in enumerate(tqdm(dataset)):\n",
    "    data_to_ingest = [{ \"_index\": hybrid_search_index_name, \"_id\": str(key + 1), \"embeddings\": data[\"embedding\"], \"text\": data['text']}]\n",
    "    (res, errors) = bulk(client, data_to_ingest)\n",
    "    if len(errors) != 0:\n",
    "        print(errors)\n",
    "        global_errors.append(errors)\n",
    "\n",
    "\n",
    "print(f\"Ingestion completed. Errors: {global_errors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.indices.refresh(index=hybrid_search_index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a basic example of how to do hybrid search using bool query. In the example vector is generated outside of OpenSearch.\n",
    "#\n",
    "queries = [\n",
    "    {\n",
    "        \"query\": \"Give me inspirational quotes about overcoming doubts.\",\n",
    "        \"expectedResponse\": \"The only limit to our realization of tomorrow will be our doubts of today.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Quotes about a simple life without complications.\",\n",
    "        \"expectedResponse\": \"Life is really simple, but we insist on making it complicated.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def pretty_print_search_response(query, query_response):\n",
    "    print(f\"Query : {query['query']}\")\n",
    "    print(f\"Expected Response: {query['expectedResponse']}\")\n",
    "    print(f\"Actual Response : {query_response['hits']['hits'][0]['fields']['text'][0]}\")\n",
    "    print('\\n')\n",
    "\n",
    "for query in queries:\n",
    "    query_body = {\n",
    "        \"size\": 1,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": [\n",
    "                    {\n",
    "                        \"match\": {\n",
    "                            \"text\": query[\"query\"]\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"knn\": {\n",
    "                            \"embeddings\" : { \n",
    "                                \"vector\": model.encode(query['query']),\n",
    "                                \"k\": 10\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"_source\": \"false\",\n",
    "        \"fields\": [\"text\"]\n",
    "    }\n",
    "\n",
    "    response = client.search(index=hybrid_search_index_name, body=query_body)\n",
    "    \n",
    "    pretty_print_search_response(query=query, query_response=response)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensearch-examples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
